# Chapter 4: Simulating Physics, Gravity, and Collisions in Gazebo — Lesson Plan

**Generated by**: chapter-planner v2.0.0 (Reasoning-Activated)
**Source Spec**: specs/book/part-2-spec.md
**Created**: 2025-12-16
**Constitution**: v6.0.1 (Reasoning Mode)

---

## I. Chapter Analysis

### Chapter Type
**Technical/Code-Focused** — Gazebo physics simulation and configuration. Chapter teaches implementation skills (spawning models, configuring physics parameters, implementing collision detection, controlling simulated robots). Learning objectives emphasize "apply," "implement," "configure" (action verbs indicating Layer 1-3 progression). Code examples and practical exercises required throughout.

### Concept Density Analysis

**Core Concepts** (from spec): 7 major concepts
1. Gazebo architecture (server, client, plugins)
2. Physics engines (ODE, Bullet, DART selection and configuration)
3. World files (SDF format and structure)
4. Model spawning (spawn_entity service, URDF integration)
5. Collision detection (contact sensors, collision callbacks)
6. Gravity and friction configuration (physics parameters)
7. Gazebo-ROS 2 bridge (communication between simulator and control nodes)

**Complexity Assessment**: **Standard** — 7 concepts, moderate complexity. Each concept builds on previous (architecture → physics selection → world files → spawning → sensing → control). No advanced mathematical modeling required; focus on configuration and integration. Prerequisites from Part 1 (URDF, ROS 2 topics/services) provide foundation.

**Proficiency Tier**: B1-B2 (Intermediate Foundation to Application) from chapter-index.md
- B1: Can apply configuration patterns with guidance
- B2: Can troubleshoot and customize parameters independently

**Justified Lesson Count**: 8 lessons
- Layer 1 (Manual): 2 lessons (architecture understanding, world file creation)
- Layer 2 (AI Collaboration): 3 lessons (model spawning, physics tuning, collision handling)
- Layer 3 (Intelligence Design): 2 lessons (reusable simulation configuration skill, joint control patterns)
- Layer 4 (Capstone): 1 lesson (humanoid standing and balancing simulation project)
- **Total**: 8 lessons

**Reasoning**: Concept density (7 concepts) justifies ~8 lessons at B1 proficiency. Standard complexity suggests 2-3 lessons per stage. Manual foundation establishes Gazebo ecosystem; AI collaboration layers teach configuration through bidirectional learning; Intelligence Design encodes reusable patterns; Layer 4 integrates all concepts into humanoid control project.

---

## II. Success Criteria (from Part 2 Spec)

### Technical Success Evals
- **Eval-4.1**: Students configure Gazebo worlds with custom physics parameters
- **Eval-4.2**: Students spawn URDF models into Gazebo simulation
- **Eval-4.3**: Students implement collision detection and response
- **Eval-4.4**: Students control simulated humanoid via ROS 2 topics
- **Eval-4.5**: Students debug physics issues (penetration, instability)

### Pedagogical Success
- [ ] All lessons follow 4-layer teaching framework
- [ ] Show-then-explain pattern in every lesson
- [ ] "Try With AI" sections demonstrate AI collaboration (no meta-commentary)
- [ ] Exercises have checkbox success criteria
- [ ] Capstone integrates chapter concepts

---

## III. Lesson Sequence

### Lesson 1: Gazebo Architecture and Ecosystem (Layer 1: Manual Foundation)

**Learning Objective**: Understand Gazebo's client-server architecture, plugin system, and ecosystem by exploring and analyzing a working simulation.

**Stage**: 1 (Manual Foundation)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 — within B1 limit of 7-10):
1. Gazebo server (gzserver) and client (gzclient) separation
2. Plugin system architecture (physics, sensor, system plugins)
3. SDF (Simulation Description Format) file structure
4. ROS 2 integration via gazebo_ros package
5. Gazebo world files vs model files vs URDF files

**Cognitive Load Validation**: 5 concepts ≤ 10 limit (B1) → ✅ WITHIN LIMIT

**Maps to Evals**: Eval-4.1 (foundational understanding for configuration)

**Content Elements**:
- **Manual exploration**: Students install Gazebo Harmonic, examine pre-built world files in text editor
- **Architecture walkthrough**: Diagram and explanation of server-client communication, plugin loading sequence
- **No AI assistance**: Students explore file structure, understand relationships manually
- **Practice**: Students modify a simple world file (change gravity value), observe effect in running simulation
- **Checkpoint**: Students explain in their own words: "What does Gazebo server do? What does gzclient do? Why separate?"

**Prerequisites**: Part 1 completion (ROS 2 basics, URDF familiarity)

**Estimated Time**: 90 minutes

**Teaching Pattern**: Direct teaching + hands-on exploration (different from Part 1 lecture-style)

---

### Lesson 2: Creating and Modifying World Files (Layer 1: Manual Foundation)

**Learning Objective**: Create custom SDF world files by hand, understanding physics engine selection, gravity/friction configuration, and object placement.

**Stage**: 1 (Manual Foundation)

**CEFR Proficiency**: B1

**New Concepts** (count: 5 — within B1 limit):
1. SDF world structure (<?xml>, <world>, <model>, <physics>)
2. Physics engine options (ODE, Bullet, DART) and trade-offs
3. Gravity vector configuration (typically 0, 0, -9.81)
4. Friction parameters (mu1, mu2, friction coefficients)
5. Model placement (pose: position + orientation)

**Cognitive Load Validation**: 5 concepts ≤ 10 limit (B1) → ✅ WITHIN LIMIT

**Maps to Evals**: Eval-4.1 (configure physics parameters), foundational for Eval-4.2

**Content Elements**:
- **Manual world creation**: Students write SDF from scratch (not copy-paste templates)
- **Step-by-step walkthrough**: Show → explain each XML element's purpose
- **Physics engine exploration**: Students manually create 3 separate worlds (ODE, Bullet, DART), observe differences
- **Ground plane and walls**: Students add collision objects manually, understand geometry types
- **Gravity tuning**: Students modify gravity values, observe effect on dropped objects
- **No AI help yet**: Build mental models for later AI collaboration

**Prerequisites**: Lesson 1 (Gazebo architecture understanding)

**Estimated Time**: 120 minutes

**Teaching Pattern**: Show-then-explain, hands-on creation (building confidence for Layer 2)

---

### Lesson 3: Spawning and Controlling Models with AI Assistance (Layer 2: AI Collaboration)

**Learning Objective**: Spawn URDF models into running Gazebo simulation using spawn_entity service, with AI helping troubleshoot common issues.

**Stage**: 2 (AI Collaboration with Three Roles)

**CEFR Proficiency**: B1

**New Concepts** (count: 4 — within B1 limit):
1. spawn_entity ROS 2 service interface (request/response)
2. Initial pose specification for spawning
3. Namespace management (avoiding name conflicts)
4. Failure diagnostics (error messages, debugging approaches)

**Cognitive Load Validation**: 4 concepts ≤ 10 limit (B1) → ✅ WITHIN LIMIT

**Maps to Evals**: Eval-4.2 (spawn URDF models), Eval-4.5 (debug issues)

**Three Roles Demonstrations** (REQUIRED):

1. **AI as Teacher**:
   - *Scenario*: Student writes spawn_entity call that fails with "model not found" error
   - *AI teaches*: "The URDF file path is relative, not absolute. In Gazebo, you need the complete path or use the GAZEBO_MODEL_PATH environment variable. Here's the pattern: [shows correct approach]"
   - *Learning*: Student learns path resolution best practice they didn't know

2. **AI as Student**:
   - *Scenario*: AI suggests spawning all models at origin (0, 0, 0), creating overlap collision
   - *Student teaches*: "In our scenario, robots need separate spawn positions. Here's the placement constraint: [specifies positions for scene]"
   - *Adaptation*: AI generates spawn commands with correct positions

3. **AI as Co-Worker**:
   - *Scenario*: Student and AI iterate on spawn timing
   - *Iteration 1*: Student spawns humanoid immediately after gazebo launches → crashes (world not ready)
   - *Iteration 2*: AI suggests delay → works but slow
   - *Iteration 3*: Together identify using `/clock` subscriber to detect world readiness → elegant solution
   - *Convergence*: Neither knew optimal solution initially; iteration produced better result

**Content Elements**:
- **Recap Layer 1**: Review spawn_entity service from ROS 2 documentation
- **Manual attempt**: Student writes first spawn command (will fail in specific way)
- **AI collaboration**: Show all three roles above
- **Practice exercise**: Students spawn multiple models with AI assistance, debug placement issues
- **Testing checkpoint**: Verify spawned models are in correct positions and not penetrating collision objects

**Prerequisites**: Lessons 1-2 (Gazebo fundamentals)

**Estimated Time**: 120 minutes

---

### Lesson 4: Physics Parameter Tuning with AI Collaboration (Layer 2: AI Collaboration)

**Learning Objective**: Configure and tune physics parameters (gravity, damping, friction) to achieve realistic humanoid behavior using AI as collaborative tuning partner.

**Stage**: 2 (AI Collaboration with Three Roles)

**CEFR Proficiency**: B1-B2

**New Concepts** (count: 5 — within B1 limit):
1. Physics timestep (step size, iterations per step)
2. Damping parameters (linear, angular velocity damping)
3. Friction models and coefficients
4. Contact physics (restitution, bounce behavior)
5. Stability tuning (penetration tolerance, solver iterations)

**Cognitive Load Validation**: 5 concepts ≤ 10 limit (B1) → ✅ WITHIN LIMIT

**Maps to Evals**: Eval-4.1 (configure physics), Eval-4.5 (debug instability)

**Three Roles Demonstrations** (REQUIRED):

1. **AI as Teacher**:
   - *Scenario*: Student's simulated humanoid wobbles unrealistically during stance
   - *AI teaches*: "High damping prevents realistic motion, but low damping causes instability. The pattern is: start conservative (high damping), gradually reduce while monitoring joint oscillations. Use contact penetration threshold to catch early instability signs."
   - *Learning*: Student learns physics tuning heuristics

2. **AI as Student**:
   - *Scenario*: AI suggests very low timestep (0.0001) for stability
   - *Student corrects*: "That's too computationally expensive for real-time simulation. We need balance between accuracy and speed."
   - *AI adapts*: Generates compromise values with explanation

3. **AI as Co-Worker**:
   - *Scenario*: Humanoid feet penetrate ground during stance
   - *Iteration 1*: Increase friction → better but still penetrates
   - *Iteration 2*: Reduce contact penetration tolerance → helps
   - *Iteration 3*: Combined approach + joint limit tuning → stable stance
   - *Convergence*: Multi-parameter optimization needed; iteration discovered correct combination

**Content Elements**:
- **Physics tuning challenge**: Humanoid exhibits unrealistic behavior (provide test scenario)
- **Parameter space exploration**: Students systematically vary parameters, observe effects
- **AI collaboration**: Use AI to accelerate finding stable configuration
- **Documentation**: Students record which parameters affect which behaviors
- **Validation**: Humanoid stands stably without penetration or excessive oscillation

**Prerequisites**: Lessons 1-3 (Gazebo and spawning)

**Estimated Time**: 120 minutes

---

### Lesson 5: Collision Detection and Contact Sensing (Layer 2: AI Collaboration)

**Learning Objective**: Implement contact sensors on humanoid and process collision events via ROS 2 topics using AI-assisted debugging.

**Stage**: 2 (AI Collaboration with Three Roles)

**CEFR Proficiency**: B1-B2

**New Concepts** (count: 5 — within B1 limit):
1. Contact sensor plugin (sensor type = "contact")
2. Collision bits and filtering (collide_bitmask)
3. ROS 2 sensor message types (ContactsState)
4. Processing contact events (force, contact points)
5. Debugging sensor data (RViz visualization, message inspection)

**Cognitive Load Validation**: 5 concepts ≤ 10 limit (B1) → ✅ WITHIN LIMIT

**Maps to Evals**: Eval-4.3 (implement collision detection), Eval-4.5 (debug sensor issues)

**Three Roles Demonstrations** (REQUIRED):

1. **AI as Teacher**:
   - *Scenario*: Student adds contact sensor but receives no messages despite collisions
   - *AI teaches*: "Contact sensors only publish when collision CHANGES (contact made or broken). If you have continuous contact, there's no message. Use rate-based publishing or track state changes explicitly."
   - *Learning*: Student learns sensor message generation patterns

2. **AI as Student**:
   - *Scenario*: AI suggests monitoring all contacts
   - *Student corrects*: "We only care about foot-ground contact. Filter by link names to reduce noise."
   - *AI adapts*: Updates sensor configuration with filtering

3. **AI as Co-Worker**:
   - *Scenario*: Determining foot contact for walking controller
   - *Iteration 1*: Use contact force magnitude threshold → too sensitive to noise
   - *Iteration 2*: Use contact normal direction → more reliable
   - *Iteration 3*: Combine both + hysteresis → robust detection
   - *Convergence*: Multi-signal fusion approach better than single sensor

**Content Elements**:
- **Sensor URDF**: Add contact sensor to humanoid foot links
- **Plugin configuration**: Enable contact plugin in Gazebo world
- **Message inspection**: Use `ros2 topic echo` to observe contact data
- **RViz visualization**: Display contact points in 3D visualization
- **Python processing**: Write ROS 2 node to process contact events
- **Testing**: Verify contacts detected during walk, jumping, falling scenarios

**Prerequisites**: Lessons 1-4 (Gazebo fundamentals, spawning, physics tuning)

**Estimated Time**: 120 minutes

---

### Lesson 6: Joint Control and Humanoid Movement (Layer 3: Intelligence Design)

**Learning Objective**: Create reusable humanoid joint control skill that encapsulates patterns from Lessons 1-5, enabling reliable control via ROS 2 joint trajectory controller.

**Stage**: 3 (Intelligence Design)

**CEFR Proficiency**: B2

**Reusable Artifact Created**: **gazebo-humanoid-control-skill**
- Encapsulates: joint trajectory controller setup, command publishing patterns, feedback monitoring
- Reusable across: Any humanoid model, different robot controllers, future chapters
- Format: `.claude/skills/gazebo-humanoid-control/SKILL.md`

**Maps to Evals**: Eval-4.4 (control humanoid via ROS 2)

**Content Elements**:
- **Pattern recognition**: Review Lessons 1-5, identify recurring control patterns
- **Skill design**: Use Persona + Questions + Principles pattern
  - *Persona*: "Think like a roboticist standardizing humanoid control interfaces"
  - *Questions*:
    - What joint constraints exist (speed, acceleration limits)?
    - How do we handle controller timeouts gracefully?
    - What feedback signals indicate successful execution?
  - *Principles*:
    - Separation of concerns: Joint group control separate from individual joint manipulation
    - Graceful degradation: Continue functioning even if some joints fail
    - Feedback validation: Always verify goal achievement before next command
- **Implementation**: Document standard patterns for:
  - Single joint control (setpoint commands)
  - Multi-joint trajectories (interpolated movement)
  - Safety monitoring (timeout detection, out-of-range rejection)
  - Feedback processing (actual vs desired comparison)
- **Testing**: Apply skill to control humanoid arm reaching, standing, simple movement

**Prerequisites**: Lessons 1-5 (all Gazebo and control fundamentals)

**Estimated Time**: 90 minutes

---

### Lesson 7: Debugging and Optimization (Layer 3: Intelligence Design)

**Learning Objective**: Create reusable debugging skill for physics simulation issues, encapsulating Eval-4.5 requirements for troubleshooting penetration, instability, and sensor problems.

**Stage**: 3 (Intelligence Design)

**CEFR Proficiency**: B2

**Reusable Artifact Created**: **gazebo-physics-debugging-skill**
- Encapsulates: diagnostic workflows, tuning decision trees, common issue patterns
- Reusable across: Any Gazebo simulation, future physics-heavy chapters
- Format: `.claude/skills/gazebo-physics-debugging/SKILL.md`

**Maps to Evals**: Eval-4.5 (debug physics issues)

**Content Elements**:
- **Problem categorization**:
  - Penetration issues (objects sinking through terrain)
  - Oscillation/instability (uncontrolled wobbling)
  - Performance problems (simulation running slowly)
  - Contact detection failures (sensors not triggering)
- **Decision tree creation**:
  - "If penetration occurs during contact: Check [these parameters]"
  - "If instability after spawning: Try [this sequence]"
  - "If performance degraded: Profile [these metrics]"
- **Tool utilization patterns**:
  - Using RViz to visualize physics debug information
  - Interpreting Gazebo log output (gzserver console)
  - Incremental parameter changes to isolate causes
- **Testing**: Present problematic simulation scenarios, students apply skill to diagnose and fix

**Prerequisites**: Lessons 1-6 (all Gazebo and control fundamentals)

**Estimated Time**: 90 minutes

---

### Lesson 8: Capstone — Humanoid Standing and Balancing in Simulation (Layer 4: Spec-Driven Integration)

**Learning Objective**: Design and implement complete humanoid standing and balancing behavior through specification-first approach, composing gazebo-humanoid-control-skill and gazebo-physics-debugging-skill.

**Stage**: 4 (Spec-Driven Integration)

**CEFR Proficiency**: B2

**Maps to Evals**: ALL (Eval-4.1 through Eval-4.5 integrated)

**Content Elements**:

1. **Specification Writing** (PRIMARY SKILL — BEFORE ANY CODE):
   - *Intent*: Design spec.md describing standing behavior requirements
   - *Constraints*:
     - Humanoid must stand stably on flat ground
     - Must maintain balance for 5+ seconds without falling
     - Must tolerate minor external pushes (simulated disturbances)
     - Must achieve this using only joint trajectory commands (no active force control)
   - *Success criteria*:
     - Center of mass projection stays within foot polygon
     - Joint angles remain within safe operating range
     - No foot penetration of ground
   - *Acceptance tests*:
     - `test_stable_standing_duration`: 10 seconds without falling
     - `test_foot_contact`: Both feet maintain contact with ground
     - `test_balance_recovery`: After simulated push, returns to stable pose within 2 seconds

2. **Component Composition**:
   - Which skills from Lessons 6-7 apply?
     - gazebo-humanoid-control-skill: YES (joint trajectory commands)
     - gazebo-physics-debugging-skill: YES (stability tuning)
   - New components needed:
     - Simple balance feedback loop (read foot contact sensors → adjust joint angles)
   - Architecture: Spec → Composed skills + balance logic → ROS 2 controller node

3. **AI Orchestration**:
   - Student provides spec.md to AI
   - AI generates controller implementation using composed skills
   - Implementation uses gazebo-humanoid-control-skill for commands, gazebo-physics-debugging-skill for stability tuning
   - Student validates against spec acceptance tests

4. **Iterative Refinement**:
   - Iteration 1: Basic stance control (succeeds at standing, fails at push recovery)
   - Student feedback: "Must handle disturbances"
   - Iteration 2: Add balance feedback loop
   - Result: Meets all success criteria

5. **Convergence**:
   - Neither student nor AI had complete controller design at start
   - Specification + composed components + iteration = robust humanoid control
   - Students document lessons learned, improvements for future implementation

**Prerequisites**: Lessons 1-7 (all foundational and intelligence design lessons)

**Estimated Time**: 150 minutes (1.5 hours teaching + 1.5 hours hands-on)

---

## IV. Skill Dependencies

**Skill Dependency Graph**:
```
Gazebo architecture (Lesson 1)
    ↓
World file creation (Lesson 2)
    ↓
Model spawning (Lesson 3)
    ↓
Physics tuning (Lesson 4)
    ↓
Contact sensing (Lesson 5)
    ↓
gazebo-humanoid-control-skill (Lesson 6)
    ├─→ gazebo-physics-debugging-skill (Lesson 7)
    └─→ Capstone project (Lesson 8)
```

**Cross-Chapter Dependencies**:
- Chapter 4 assumes: Part 1 completion (URDF knowledge, ROS 2 topics/services)
- Chapter 4 provides: Gazebo simulation foundation for Chapters 5-6
- Chapter 4 reuses: URDF humanoid model from Part 1 Chapter 3

**Validation**:
- ✅ Part 1 chapters implemented (prerequisite met)
- ✅ Lesson order respects skill dependencies
- ✅ Reusable skills from Lessons 6-7 composed in Layer 4 capstone

---

## V. Assessment Plan

### Formative Assessments (During Lessons)

- **Lesson 1**: Explain architecture (checkpoint)
- **Lesson 2**: Create custom world file with configured physics
- **Lesson 3**: Successfully spawn humanoid URDF into simulation
- **Lesson 4**: Achieve stable humanoid stance through physics tuning
- **Lesson 5**: Detect foot-ground contact reliably via sensor
- **Lesson 6**: Apply gazebo-humanoid-control-skill in practice scenario
- **Lesson 7**: Diagnose and fix physics instability in provided scenario

### Summative Assessment (End of Chapter)

- **Lesson 8 Capstone**: Humanoid standing and balancing project
  - ✅ Spec written first (demonstrates specification skill)
  - ✅ All acceptance tests pass (objective success)
  - ✅ Uses composed skills (demonstrates intelligence composition)
  - ✅ Student can articulate design decisions (demonstrates reasoning)

**Assessment Alignment**: All assessments align with CEFR B1-B2 proficiency (apply/analyze cognitive levels), matching Constitution Principle 3.

---

## VI. Validation Checklist

**Chapter-Level Validation**:
- [x] Chapter type identified (Technical/Code-Focused)
- [x] Concept density analysis documented (7 concepts → 8 lessons justified)
- [x] Lesson count justified by density, not arbitrary
- [x] All evals from spec covered by lessons (Eval-4.1 through Eval-4.5)
- [x] All lessons map to at least one eval

**Stage Progression Validation**:
- [x] Lessons 1-2: Layer 1 (Manual foundation, no AI)
- [x] Lessons 3-5: Layer 2 (AI Collaboration with Three Roles)
- [x] Lessons 6-7: Layer 3 (Intelligence Design, reusable skills)
- [x] Lesson 8: Layer 4 (Spec-Driven Integration, capstone)
- [x] Spec-first ONLY in Layer 4 (not earlier)

**Cognitive Load Validation**:
- [x] Lesson 1: 5 concepts ≤ 10 limit → ✅
- [x] Lesson 2: 5 concepts ≤ 10 limit → ✅
- [x] Lesson 3: 4 concepts ≤ 10 limit → ✅
- [x] Lesson 4: 5 concepts ≤ 10 limit → ✅
- [x] Lesson 5: 5 concepts ≤ 10 limit → ✅
- [x] Lesson 6: Intelligence design (no new concept count)
- [x] Lesson 7: Intelligence design (no new concept count)
- [x] Lesson 8: Capstone (integration, no new concepts)

**Dependency Validation**:
- [x] Skill dependencies satisfied by lesson order
- [x] Cross-chapter dependencies validated (Part 1 → Part 2 progression)

**Teaching Pattern Validation**:
- [x] Lesson 1: Direct teaching + exploration (shows Gazebo files, explains architecture)
- [x] Lesson 2: Show-then-explain (create world files step-by-step)
- [x] Lessons 3-5: AI Collaboration (Three Roles explicit in plan)
- [x] Lessons 6-7: Intelligence Design (skill creation with reasoning)
- [x] Lesson 8: Specification-first capstone
- [x] Pattern varies from Part 1 (Part 1 was tutorial-style; Part 2 is hands-on discovery + AI collab)

---

## VII. Chapter Success Metrics

**This chapter succeeds when:**
- ✅ Humanoid URDF from Part 1 loads and simulates stably in Gazebo (SC-2.1)
- ✅ Physics simulation shows no penetration or unrealistic behavior (SC-2.2)
- ✅ All evaluation criteria (Eval-4.1 through Eval-4.5) achieved by students
- ✅ Reusable skills created (gazebo-humanoid-control-skill, gazebo-physics-debugging-skill)
- ✅ Capstone project demonstrates complete humanoid control workflow

---

**Chapter 4 Plan — Ready for Content Implementation**

Total estimated content time: 8 lessons × 90-120 minutes = 12-16 hours
Includes: Lecture, hands-on practice, AI collaboration, skill design, capstone project
